#one-step 
#spatiotemporal-features 
	#textural-features 
#discrete-pain 

| 技术路线                                                                                       | 简评  | 学习任务 | 数据集  |
| ------------------------------------------------------------------------------------------ | --- | ---- | ---- |
| 无监督学习：自监督学习<br>多模态：VGG16提取空间特征，LSTM提取时间特征<br>可解释性：Grad-CAM识别检测的关键区域<br>泛化能力：boosting技术<br> |     |      | 序列级别 |


-------
# 现状综述
**研究发展**
1. 经典机器学习方法
2. 早期深度学习方法
3. 具有多模态和注意力机制的现代深度学习

**不足**
- 单一模态受限
- 计算效率低，高计算要求
- 不同人群的普适性有限
- 未满足实时需要
- 对注释数据集的依赖
- 不具有可解释性
# 技术步骤
## 预处理数据
1. 标准化所有视频文件
	1. 帧速率、分辨率的一致性
	2. 正则化处理
	3. 增强技术：轻微旋转、亮度变化、网格扭曲等。`旋转3度、宽度和高度移动3%、缩放变化5%、亮度变化在原始值的90%-110%之间。`
2. 疼痛等级（No Pain, Mild Pain, Moderate Pain, Severe Pain, and Extreme Pain）：数据集的疼痛等级被映射到四个等级。
3. Grad-CAM：生成聚焦区域图，确保模型聚焦于关键部位，如眼睛、鼻子、嘴巴等。
## 特征提取
### 面部特征点/几何特征
1. 使用MediaPipe Face Mesh toolkit：其中的FaceMeshDetector类能找到面部上的468个精确点。
	- static_image_mode=False：在视频帧移动时跟踪特征点。
	- min_detection_confidence=0.7+min_tracking_confidence=0.7：确保识别平衡。
2. 特征向量构造：每帧的关键点转换为x,y,z坐标，缩放以匹配帧的大小。然后这些坐标被展成一致solid特征向量
### 深度特征

# 研究结果
1. 与CNN-LSTM模型相比，该框架的准确性提高了12.5%，误报率降低了20%。
2. AUC为0.99，准确度为99%。

**优势**
- 多模态
- 部署于边缘设备，适用于远程医疗（网络延迟、视频质量起伏、硬件限制）：混合时空建模
- 不同人群通用性：分层抽样、类权重、数据增强
# 数据集
- BioVid dataset（多种疼痛刺激，主要）：87名受试者（43名女性，年龄范围20-65岁，44名男性，年龄范围20-64岁）的17300个视频剪辑。高质量的1080 p摄像机和同步生理传感器。大约20000帧代表五种疼痛类别中的每一种。
- UNBC-McMaster Shoulder Pain Archive（特异性）：25名慢性肩痛受试者（13名女性和12名男性，共48000帧）的200个视频样本，以及详细的疼痛评分、FACS（面部动作编码系统）和VAS（视觉模拟量表）。用于评价和测试阶段。
- MIntPAIN dataset（真实世界延迟）：使用同步RGB、深度和热成像相机记录的20名健康成年人（年龄范围22-42岁）的多模态数据集，提供了五种不同的疼痛水平。
