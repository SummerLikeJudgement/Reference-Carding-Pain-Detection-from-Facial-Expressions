2024-1-C刊：[[multi-modal fusion of facial features and video streams.pdf]]
#discrete-pain
#SPR —— #vedio 

| 技术路线                                                                                                                                   | 简评     | 学习任务 | 数据集  |
| -------------------------------------------------------------------------------------------------------------------------------------- | ------ | ---- | ---- |
| 无监督学习：自监督学习<br>多模态：mediapipe识别面部和landmark后，VGG16提取纹理特征特征，BiLSTM提取时间上的几何特征，二者连接后输入全连接层<br>可解释性：Grad-CAM识别检测的关键区域<br>泛化能力：boosting技术<br> | 技术相对过时 |      | 序列级别 |


-------
# 现状综述
**研究发展**
1. 经典机器学习方法
2. 早期深度学习方法
3. 具有多模态和注意力机制的现代深度学习

**不足**
- 单一模态受限
- 计算效率低，高计算要求
- 不同人群的普适性有限
- 未满足实时需要
- 对注释数据集的依赖
- 不具有可解释性
# 技术步骤
## 预处理数据
1. 标准化所有视频文件
	1. 帧速率、分辨率的一致性
	2. 正则化处理
	3. 增强技术：轻微旋转、亮度变化、网格扭曲等。`旋转3度、宽度和高度移动3%、缩放变化5%、亮度变化在原始值的90%-110%之间。`
2. 疼痛等级（No Pain, Mild Pain, Moderate Pain, Severe Pain, and Extreme Pain）：数据集的疼痛等级被映射到四个等级。
3. Grad-CAM：生成聚焦区域图，确保模型聚焦于关键部位，如眼睛、鼻子、嘴巴等。
## 特征提取
### 面部检测
1. 使用MediaPipe Face Mesh toolkit：其中的FaceMeshDetector类能找到面部上的468个精确点。
	- static_image_mode=False：在视频帧移动时跟踪特征点。
	- min_detection_confidence=0.7+min_tracking_confidence=0.7：确保识别平衡。
2. 特征向量构造：每帧的关键点转换为x,y,z坐标，缩放以匹配帧的大小。然后这些坐标被展成一致solid特征向量。
	1. 多个视频帧的关键点x,y,z坐标堆叠成一个特征向量，转发到BiLSTM部分。
	2. 单个视频帧的面部剪切缩放为`224*224`的图像，转发到VGG部分。

- Mediapipe是已训练的
### VGG分支（空间特征-纹理特征）
1. torchvision提供的预训练VGG16网络（使用ImageNet训练）仅保留卷积层(features)结构。
2. 全局平均池化（GAP）将输出的特征图转化为特征向量，浓缩图像的高层语义信息。
3. SE提升有用的特征并抑制对当前任务用处不大的特征。

- VGG16已通过ImageNet预训练
### BiLSTM分支（时间特征-几何+纹理特征）
1. BiLSTM提取视频帧的时间几何特征。
2. 在BiLSTM中添加多头注意力机制。
### 后期融合

# 研究结果
1. 与CNN-LSTM模型相比，该框架的准确性提高了12.5%，误报率降低了20%。
2. AUC为0.99，准确度为99%。

**优势**
- 多模态
- 部署于边缘设备，适用于远程医疗（网络延迟、视频质量起伏、硬件限制）：混合时空建模
- 不同人群通用性：分层抽样、类权重、数据增强
# 数据集
- BioVid dataset（多种疼痛刺激，主要）：87名受试者（43名女性，年龄范围20-65岁，44名男性，年龄范围20-64岁）的17300个视频剪辑。高质量的1080 p摄像机和同步生理传感器。大约20000帧代表五种疼痛类别中的每一种。
- UNBC-McMaster Shoulder Pain Archive（特异性）：25名慢性肩痛受试者（13名女性和12名男性，共48000帧）的200个视频样本，以及详细的疼痛评分、FACS（面部动作编码系统）和VAS（视觉模拟量表）。用于评价和测试阶段。
- MIntPAIN dataset（真实世界延迟）：使用同步RGB、深度和热成像相机记录的20名健康成年人（年龄范围22-42岁）的多模态数据集，提供了五种不同的疼痛水平。
